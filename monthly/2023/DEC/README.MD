# Readings

## Optimizing Java. Practical Techniques for Improving JVM Application Performance (ISBN: 978-1-49-203927-3)

Chapter 10. Understanding JIT Compilation

- The majority of techniques described are specific to HotSpot and there is no guarantee they are implemented in other
  JVMs.
- Interpreted methods are not suitable targets for serious optimization. Analyzed methods should be eligible for
  compilation.
- The primary tool used to understand and visualise internals of JIT compilation in JVM is __JITWatch__. It helps to
  explain specific JIT optimizations and features. Effects can be observed in JITWatch. It allows following what exactly
  happened to the bytecode, makes it possible to tune compilation switches and measure effects. Analysis is possible by
  monitoring detailed HotSpot compilation log. JITWatch also provides sandbox capability. Sandbox allows quick
  prototyping and observing JIT decisions. It gives a fast feedback of how small changes can affect the optimization
  choices. In sandbox one can experiment with the VM switches controlling JIT. But they should not be introduced on
  production without extensive testing. But the code run in sandbox may behave differently than in a real application.
  That's because of limited context: small pieces of code can have limited capabilities of further optimization than the
  real code in broad context. JITWatch also allows visualizing how compiled methods are placed in the code cache.
- Java 8 and earlier stores profiled compiled methods, non-profiled compiled methods, VM native code in a single region.
  Since Java 9 code cache is segmented for different types of native code stored in different regions.
- To dive deeper into statistics and tuning of JIT it may be necessary to use a __debug JVM__. It adds additional cost
  of performance. Inspecting disassembled native code is possible using a disassembly binary, like __hsdis__.
- Profile-guided optimization information is stored in __method data objects__ (MDOs). They are used by the bytecode
  interpreter and C1 compiler to decide what optimizations should be made. MDOs store information like methods invoked,
  branches, observed types. The compiler then builds the internal representation of the code, which is different
  depending on compiler (C1/C2). The compiler uses this internal representation to perform heavy optimization.
- Optimizations are dependent on runtime information. The two JIT compilers apply different optimization techniques. C1
  doesn't perform speculative optimizations. C2, in contrary, makes assumptions based on runtime execution and uses
  these assumptions to make optimization decisions. Assumptions are protected by __guards__. If the guard is failed, the
  assumption is considered incorrect and the compiled code must be removed as it is considered unsafe.
- __Inlining__ is a process of copying the content of called method in place of invocation. There are limits put on
  inlining for JVM. Otherwise, compiler could be tied up inlining very deep. Several factors are taken into
  consideration while taking inlining decision, including: bytecode size, depth, amount of space in the code cache.
  Inlining behavior may be controlled with JVM switches.
- __Loop unrolling__ allows reducing the number of times of jumping back to the beginning.
- __Escape analysis__ is assessing if the work done within a method has effects outside of that method.
- __Scalar replacement__ optimization may be applied to an object which doesn't escape the method. VM threats objects as
  they had all been local variables. This technique reduces heap allocation replacing it with objects' attributes
  allocation on stack. If an object escapes the method scope on any branch, this optimization will not be applied.
- __Monomorphic dispatch__ means using a single form. Very often only one runtime receiver type is observed. For such
  cases looking up methods in vtables can be eliminated and _invokevirtual_ instructions may be replaced with a quick
  type test (the guard). The guard is checked before every call instruction and ensures that no incorrect code is
  executed.
- __Intrinsic__ is a highly tuned native implementation of methods preknown to JVM rather than generated dynamically by
  JIT. They are usually performance-critical methods using specific features of the OS or CPU architectures (they are
  platform-specific). It's possible to create new intrinsic, but the tradeoff of adding complexity must be assessed
  versus the likelihood of the intrinsic being intensively used.
- __On-stack replacement__ is an optimization technique for hot loops within methods not called frequently enough
  (like _main()_). Loop back branches are counted and if a threshold is acquired, the interpreted loop will be compiled.
- __Safepoints__ are usually generated by HotSpot at loop back branches and on method return. That means, when a loop is
  computation intensive, then for some threads acquiring a safepoint takes significant amount of time.
- Keeping methods small may be beneficial not only due to readability reasons. It also increases the potential of method
  inlining. Also, there is a limit of bytecode size of methods to compile them, by default 8000 bytes.

# Projects

## ACTracker

- Domain entity factories were [introduced](https://github.com/marcinciapa/actracker-api/pull/146) in actracker-api.
- Domain refactoring was performed in several steps in actracker-api:
  [moving entity edit preconditions validation](https://github.com/marcinciapa/actracker-api/pull/147),
  [removing entity edit operations](https://github.com/marcinciapa/actracker-api/pull/148)

# Tutorials

- 
